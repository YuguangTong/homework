{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_reset():\n",
    "    try:\n",
    "        sess.close()\n",
    "    except:\n",
    "        pass\n",
    "    tf.reset_default_graph()\n",
    "    return tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.contrib.layers.l2_regularizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(data):\n",
    "    inputs = data['observations']\n",
    "    outputs = np.squeeze(data['actions'], axis=1)\n",
    "    input_dim = inputs.shape[-1]\n",
    "    output_dim = outputs.shape[-1]\n",
    "    return inputs, outputs, input_dim, output_dim\n",
    "\n",
    "def create_model(input_dim, output_dim, reg=1e-6):\n",
    "    input_ph = tf.placeholder(dtype=tf.float32, shape=[None, input_dim])\n",
    "    output_ph = tf.placeholder(dtype=tf.float32, shape=[None, output_dim])\n",
    "\n",
    "    layer = tf.layers.dense(input_ph, 64, \n",
    "                            activation=tf.nn.relu,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=reg),\n",
    "                            name='hidden_layer_1'\n",
    "                           )\n",
    "    layer = tf.layers.dense(layer, 128, \n",
    "                            activation=tf.nn.relu,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=reg),\n",
    "                            name='hidden_layer_2'\n",
    "                           ) \n",
    "    layer = tf.layers.dense(layer, 64, \n",
    "                            activation=tf.nn.relu,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=reg),\n",
    "                            name='hidden_layer_3'\n",
    "                           ) \n",
    "    layer = tf.layers.dense(layer, output_dim,\n",
    "                            kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                            kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=reg),\n",
    "                            name='output_layer'                            \n",
    "                           )\n",
    "    output_pred = layer                         \n",
    "    return input_ph, output_ph, output_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "envname = 'Hopper-v2'\n",
    "batch_size = 128\n",
    "learning_rate=.001\n",
    "\n",
    "train_dir = '/tmp/cs294_hw1/behavior_cloning'\n",
    "rollouts_data_dir = 'expert_data/'\n",
    "\n",
    "checkpoint_dir = os.path.join(train_dir, envname)\n",
    "if not tf.gfile.Exists(checkpoint_dir):\n",
    "    tf.gfile.MakeDirs(checkpoint_dir)\n",
    "model_path = os.path.join(checkpoint_dir, 'model.ckpt')\n",
    "    \n",
    "rollouts_data_filename = os.path.join(rollouts_data_dir, envname + '.pkl')\n",
    "with open(rollouts_data_filename, 'rb') as file:\n",
    "    data = pickle.load(file) \n",
    "inputs, outputs, input_dim, output_dim = generate_training_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000 loss: 2.159\n",
      "01000 loss: 0.009\n",
      "02000 loss: 0.004\n",
      "03000 loss: 0.003\n",
      "04000 loss: 0.003\n",
      "05000 loss: 0.003\n",
      "06000 loss: 0.001\n",
      "07000 loss: 0.004\n",
      "08000 loss: 0.002\n",
      "09000 loss: 0.001\n",
      "10000 loss: 0.002\n",
      "11000 loss: 0.001\n",
      "12000 loss: 0.001\n",
      "13000 loss: 0.001\n",
      "14000 loss: 0.001\n",
      "15000 loss: 0.001\n",
      "16000 loss: 0.001\n",
      "17000 loss: 0.001\n",
      "18000 loss: 0.001\n",
      "19000 loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "sess = tf_reset()\n",
    "\n",
    "input_ph, output_ph, output_pred = create_model(input_dim, output_dim)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(output_ph, output_pred)\n",
    "loss += tf.losses.get_regularization_loss()\n",
    "opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "for training_step in range(20000):\n",
    "    # get a random subset of the training data\n",
    "    indices = np.random.randint(low=0, high=len(inputs), size=batch_size)\n",
    "    input_batch = inputs[indices]\n",
    "    output_batch = outputs[indices]\n",
    "    \n",
    "    _, loss_run = sess.run([opt, loss], feed_dict={input_ph: input_batch, output_ph: output_batch})\n",
    "    \n",
    "    if training_step % 1000 == 0:\n",
    "        print('{0:05d} loss: {1:.4f}'.format(training_step, loss_run))\n",
    "        saver.save(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/cs294_hw1/behavior_cloning/Hopper-v2/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf_reset()\n",
    "input_ph, output_ph, output_pred = create_model(input_dim, output_dim)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tong/Envs/tf/lib/python3.6/site-packages/gym/envs/registration.py:14: DeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n",
      "/Users/tong/Envs/tf/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(envname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "Creating window glfw\n",
      "100/1000\n",
      "200/1000\n",
      "300/1000\n",
      "400/1000\n",
      "500/1000\n",
      "600/1000\n",
      "700/1000\n",
      "800/1000\n",
      "900/1000\n",
      "1000/1000\n",
      "returns [3782.6966728594875]\n",
      "mean return 3782.6966728594875\n",
      "std of return 0.0\n"
     ]
    }
   ],
   "source": [
    "num_rollouts = 1\n",
    "max_steps = env.spec.timestep_limit\n",
    "\n",
    "returns = []\n",
    "observations = []\n",
    "actions = []\n",
    "for i in range(num_rollouts):\n",
    "    print('iter', i)\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    totalr = 0.\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        action = sess.run([output_pred], feed_dict={input_ph: obs[None, :]})[0]\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        obs, r, done, _ = env.step(action)\n",
    "        totalr += r\n",
    "        steps += 1\n",
    "        if True:\n",
    "            env.render()\n",
    "        if steps % 100 == 0: print(\"%i/%i\"%(steps, max_steps))\n",
    "        if steps >= max_steps:\n",
    "            break\n",
    "    returns.append(totalr)\n",
    "\n",
    "print('returns', returns)\n",
    "print('mean return', np.mean(returns))\n",
    "print('std of return', np.std(returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = sess.run([output_pred], feed_dict={input_ph: obs[None, :]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3782.6966728594875]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
